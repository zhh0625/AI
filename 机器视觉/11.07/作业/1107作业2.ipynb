{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# 实验二\n",
        "加载预定义VGG16网络参数，并在Kaggle猫/狗数据集上进行微调和测试"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## 1.加载keras模块"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras import backend as K\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### 定义VGG16网络结构\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "scrolled": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.\u003clocals\u003e.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        }
      ],
      "source": "img_width, img_height \u003d 150, 150\nif K.image_data_format() \u003d\u003d \u0027channels_first\u0027:\n    input_shape \u003d (3, img_width, img_height)\nelse:\n    input_shape \u003d (img_width, img_height, 3)\n #定义VGG16\nmodel \u003d Sequential()\nmodel.add(ZeroPadding2D((1,1),input_shape\u003d(3,224,224)))\nmodel.add(Convolution2D(64, 3, 3, activation\u003d\u0027relu\u0027))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Convolution2D(64, 3, 3, activation\u003d\u0027relu\u0027))\nmodel.add(MaxPooling2D(pool_size\u003d(2,2), strides\u003d2,padding\u003d\u0027same\u0027))\n\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Convolution2D(128, 3, 3, activation\u003d\u0027relu\u0027))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Convolution2D(128, 3, 3, activation\u003d\u0027relu\u0027))\nmodel.add(MaxPooling2D(pool_size\u003d(2,2), strides\u003d2,padding\u003d\u0027same\u0027))\n\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Convolution2D(256, 3, 3, activation\u003d\u0027relu\u0027))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Convolution2D(256, 3, 3, activation\u003d\u0027relu\u0027))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Convolution2D(256, 3, 3, activation\u003d\u0027relu\u0027))\nmodel.add(MaxPooling2D(pool_size\u003d(2,2), strides\u003d2,padding\u003d\u0027same\u0027))\n\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Convolution2D(512, 3, 3, activation\u003d\u0027relu\u0027))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Convolution2D(512, 3, 3, activation\u003d\u0027relu\u0027))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Convolution2D(512, 3, 3, activation\u003d\u0027relu\u0027))\nmodel.add(MaxPooling2D(pool_size\u003d(2,2), strides\u003d2,padding\u003d\u0027same\u0027))\n\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Convolution2D(512, 3, 3, activation\u003d\u0027relu\u0027))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Convolution2D(512, 3, 3, activation\u003d\u0027relu\u0027))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Convolution2D(512, 3, 3, activation\u003d\u0027relu\u0027))\nmodel.add(MaxPooling2D(pool_size\u003d(2,2), strides\u003d2,padding\u003d\u0027same\u0027))\n\nmodel.add(Flatten())\nmodel.add(Dense(4096, activation\u003d\u0027relu\u0027))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(4096, activation\u003d\u0027relu\u0027))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2, activation\u003d\u0027softmax\u0027))\n    \nmodel.compile(loss\u003d\u0027categorical_crossentropy\u0027,\n              optimizer\u003d\u0027rmsprop\u0027,\n              metrics\u003d[\u0027accuracy\u0027])"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### 加载预训练权值\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": "import h5py\n#调用h5py.File函数读取预定义权值文件\nf \u003d h5py.File(\u0027models/vgg/vgg16_weights.h5\u0027)\n#加载至相应layers\nmodel_vgg\u003dvgg16(include_top\u003dFalse,weights\u003d\u0027imagenet\u0027)\nmodel_vgg\u003dvgg16_weights()\nfor k in range(f.attrs[\u0027nb_layers\u0027]):\n    if k \u003e\u003d len(model_vgg.layers) - 1:\n        # we don\u0027t look at the last two layers in the savefile (fully-connected and activation)\n        break\n    g \u003d f[\u0027layer_{}\u0027.format(k)]\n    weights \u003d [g[\u0027param_{}\u0027.format(p)] for p in range(g.attrs[\u0027nb_params\u0027])]\n    layer \u003d model_vgg.layers[k]\n\n    if layer.__class__.__name__ in [\u0027Convolution1D\u0027, \u0027Convolution2D\u0027, \u0027Convolution3D\u0027, \u0027AtrousConvolution2D\u0027]:\n        weights[0] \u003d np.transpose(weights[0], (2, 3, 1, 0))\n\n    layer.set_weights(weights)\n\nf.close()"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### 定义新加入的layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": "#定义新layers\ntop_model \u003d Sequential()\ntop_model.add(Flatten(input_shape\u003dmodel_vgg.output_shape[1:]))\ntop_model.add(Dense(256, activation\u003d\u0027relu\u0027))\ntop_model.add(Dropout(0.5))\ntop_model.add(Dense(2, activation\u003d\u0027softmax\u0027))\n\ntop_model.load_weights(\u0027models/bottleneck_40_epochs.h5\u0027)\n\nmodel_vgg.add(top_model)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### 设置不需微调的layers的trainable属性\n",
        "并调用compile函数重新编译网络"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": "#查找不参与微调的layers\nfor layer in model_vgg.layers[:25]:\n    layer.trainable \u003d False#设置其trainable属性\n\n#调用compile函数\nmodel_vgg.compile(loss\u003d\u0027categorical_crossentropy\u0027,\n              optimizer\u003d\u0027rmsprop\u0027.SGD(lr\u003d1e-4, momentum\u003d0.9),\n              metrics\u003d[\u0027accuracy\u0027])"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### 定义ImageDataGenerator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 10835 images belonging to 2 classes.\n",
            "Found 4000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_data_dir \u003d r\u0027C:\\Users\\coffe\\Desktop\\dogs-vs-cats\\train\u0027\n",
        "validation_data_dir \u003d r\u0027C:\\Users\\coffe\\Desktop\\dogs-vs-cats\\validation\u0027\n",
        "nb_train_samples \u003d 10835\n",
        "nb_validation_samples \u003d 4000\n",
        "epochs \u003d 1\n",
        "batch_size \u003d 20\n",
        "\n",
        "\n",
        "# this is the augmentation configuration we will use for training\n",
        "train_datagen \u003d ImageDataGenerator(\n",
        "    rescale\u003d1. / 255,\n",
        "    shear_range\u003d0.2,\n",
        "    zoom_range\u003d0.2,\n",
        "    horizontal_flip\u003dTrue)\n",
        "\n",
        "# this is the augmentation configuration we will use for testing:\n",
        "# only rescaling\n",
        "test_datagen \u003d ImageDataGenerator(rescale\u003d1. / 255)\n",
        "\n",
        "train_generator \u003d train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size\u003d(img_width, img_height),\n",
        "    batch_size\u003dbatch_size,\n",
        "    class_mode\u003d\u0027binary\u0027)\n",
        "\n",
        "validation_generator \u003d test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size\u003d(img_width, img_height),\n",
        "    batch_size\u003dbatch_size,\n",
        "    class_mode\u003d\u0027binary\u0027)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### 训练模型\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "scrolled": false,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "541/541 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 288s 533ms/step - loss: 0.6526 - accuracy: 0.6134 - val_loss: 0.4863 - val_accuracy: 0.7115\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\u003ckeras.callbacks.callbacks.History at 0x2b7dcbaa2e8\u003e"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_vgg.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch\u003dnb_train_samples // batch_size,\n",
        "    epochs\u003depochs,\n",
        "    validation_data\u003dvalidation_generator,\n",
        "    validation_steps\u003dnb_validation_samples // batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### 使用训练后模型预测图像\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.99895906]]\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "img \u003d cv2.resize(cv2.imread(r\u0027C:\\Users\\coffe\\Desktop\\dogs-vs-cats\\test\\7.jpg\u0027), (img_width, img_height)).astype(np.float32)\n",
        "# img[:,:,0] -\u003d 103.939\n",
        "# img[:,:,1] -\u003d 116.779\n",
        "# img[:,:,2] -\u003d 123.68\n",
        "#img \u003d img.transpose((2,0,1))\n",
        "x \u003d img_to_array(img)\n",
        "\n",
        "x \u003d np.expand_dims(x, axis\u003d0)\n",
        "\n",
        "#x \u003d preprocess_input(x)\n",
        "\n",
        "score \u003d model_vgg.predict(x)\n",
        "\n",
        "\n",
        "print(score)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "ssap_exp_config": {
      "error_alert": "Error Occurs!",
      "initial": [],
      "max_iteration": 1000,
      "recv_id": "",
      "running": [],
      "summary": [],
      "version": "1.1.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}